from scipy.io import loadmat
import numpy as np
import wave
from scipy.io import wavfile
from scipy import signal
import matplotlib.pyplot as plt

# Read the audio file
wavepath = "nokia.wav"
fs, audioIn = wavfile.read(wavepath)
audioIn = np.array(audioIn)
audioIn = audioIn / 32767

# get the length of audio file
duration = len(audioIn)

# segment into N degrees     -90 ~ 90 -> 180/5 = 36 degrees per 5degree
points_number = 36

# the number of padding zeros
remainder = duration % points_number

if remainder > 0:
    padding_zero = points_number - remainder

    audioIn = np.hstack((audioIn, np.zeros(padding_zero)))

# to calculate the new audio length and a step length for each segment
step = len(audioIn)//points_number

# Rayleigh's head shadow

# the radius of head 17/2 = 8cm
a = 8.5

# speed of sound: 340m/s
c= 34000


alpha = []   #length = 36
Tr = []      #length = 36
Tl = []      #length = 36
t = (1/2)*(a/c)

# create theta from -90 to 90 and calculate alpha which has 36 values
for theta in range(-90,90,5):
    al = (1 / 2) * (1 + np.sin(theta*np.pi/180))
    alpha.append (al)

# calculate Tr Tl which has 36 values
for i in range(len(alpha)):
    T_right = (1 - alpha[i]) * t
    Tr.append(T_right)

    T_left = alpha[i] * t
    Tl.append(T_left)

N=100        #sample points
w=[]

for k in range(-N//2,N//2):
    w1 = (np.pi * 2 * k / N) * 44100
    w.append(w1)

Hr = np.zeros((points_number,N))
Hl = np.zeros((points_number,N))

for i in range(points_number):
    H_right = np.zeros(0)
    H_left = np.zeros(0)

    for j in range(N):

        #create right hrir signal
        H_right = np.append(H_right,(1+2j * alpha[i] * w[j] * t) / (1 + 1j * w[j] * t) * np.exp(-1j * w[j] * Tr[i]))
        #create left hrir signal
        H_left  = np.append(H_left,(1+2j * (1-alpha[i]) * w[j] * t) / (1 +1j * w[j] * t) * np.exp(-1j * w[j] * Tl[i]))

    Hr[i,:] = H_right.real
    Hl[i,:] = H_left.real
    # plt.plot(range(N), Hl[i])
    # plt.plot(range(N), Hr[i])
    # plt.show()


print(alpha)

length = len(Hr[0])

# first shift
for i in range(points_number):
    Hr[i] = np.hstack((Hr[i,length//2:],Hr[i,:length//2]))
    Hl[i] = np.hstack((Hl[i,length//2:],Hl[i,:length//2]))



# do ifft
for i in range(points_number):
    Hr[i] = np.fft.ifft(Hr[i]).real
    Hl[i] = np.fft.ifft(Hl[i]).real

    # plt.plot(range(N), Hl[i])
    # plt.plot(range(N), Hr[i])
    # plt.show()

# shift back
for i in range(points_number):
    Hr[i] = np.hstack((Hr[i, length//2:], Hr[i,:length//2]))
    Hl[i] = np.hstack((Hl[i, length//2:], Hl[i,:length//2]))

    plt.plot(range(N), Hl[i])
    plt.plot(range(N), Hr[i])
    plt.show()

# init segment piece
segment_L = np.zeros((points_number,step+N-1))
segment_R = np.zeros((points_number,step+N-1))


# do the convolution in time domain
for i in range(points_number):
    # L = signal.lfilter(Hl[i,:],1,audioIn[step*i:step*(i+1)])
    # R = signal.lfilter(Hr[i,:],1,audioIn[step*i:step*(i+1)])

    L = np.convolve(Hl[i,:],audioIn[step*i:step*(i+1)])
    R = np.convolve(Hr[i,:],audioIn[step*i:step*(i+1)])

    segment_L[i,:] = L
    segment_R[i,:] = R


out_L = segment_L.reshape(-1)
out_R = segment_R.reshape(-1)
out = np.vstack((out_L,out_R))
out = out.T

wavfile.write('Hrir_Part2_Out.wav',44100,out)

# np.savetxt('Part2_HL.csv', Hl, delimiter=",")
